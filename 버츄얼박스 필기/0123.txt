가상머신 총 3대설치
	-ubuntu까지만 설치
	-이후는 x
	-계정 비번은 3개다 동일

ssh-copy-id -i ~/.ssh/id_rsa.pub kwak1@192.168.0.116
ssh-copy-id -i ~/.ssh/id_rsa.pub kwak1@192.168.0.182
ssh-copy-id -i ~/.ssh/id_rsa.pub kwak1@192.168.0.144

ssh 192.168.0.116
exit

ssh 192.168.0.182
exit

ssh 192.168.0.144
exit

d. 기타등등 필요한거 설치

vim-tiny삭제, vim설치

FTP서버 설치 - 설정 - 재시작

openJDK저장소 - 업데이트 - 설치 - 확인

sudo apt-get remove vim-tiny
sudo apt-get install vim
sudo apt-get install vsftpd
sudo vi /etc/vsftpd.conf
sudo service vsftpd restart
sudo add-apt-repository ppa:openjdk-r/ppa
sudo apt-get update
sudo apt-get install openjdk-8-jdk
java -version

----------------------

Hadoop 설치
	다운받고 알드라이브에 업로드
-------------------
압축풀기
	통일성을 위해서 폴더생성(hadoop)
		mkdir hadoop
	그 폴더로 tar.gz파일 옮겨서
		mv hadoop.3.3.3.tar.gz hadoop
	 압축풀기
		tar xvzf hadoop-3.3.3.tar.gz hadoop
	-> 압축 풀었으니 압축파일 제거
		rm -rf hadoop-3.3.3.tar.gz
---------------------------------------------------------------------

설정 파일이 있는 쪽으로 이동(최상위폴더기준)
	cd ~
	cd hadoop/hadoop-3.3.3/etc/hadoop

1. JDK위치 설정
	1) vi hadoop-env.sh
	2)'export' 검색해서 export JAVA_HOME=...
	3)a눌러서 insert모드로 바꾸고 
	4)그 줄 주석해제
	5)등호 뒤쪽에 /usr/lib/jvm/java-8-openjdk-amd64 추가
	6)저장후 종료

2. 기본설정 
	1)vi core-site.xml
	2)<configuration></configuration> 속에
	3)
<configuration>
	<property>	
		<name>fs.default.name</name>
		<value>hdfs://[NameNodeIP]:9000</value>
	</property>
	<property>	
		<name>hadoop.tmp.dir</name>
		<value>/home/[계정]/hadoopTmpData</value>
	</property>
</configuration>
	
	4)값채우고, 저장후 종료

------------------------------------------------------

3. 하둡 파일시스템 관련 설정
	1)vi hdfs-site.xml
	2)<configuration></configuration> 속에
	3)
<configuration>
	<property>	
		<name>dfs.replication</name>
		<value>[컴퓨터 수]</value> #가상머신수
	</property>
	<property>	
		<name>dfs.http.address</name>
		<value>[NameNodeIP]:50070</value>
	</property>
	<property>	
		<name>dfs.secondary.http.address</name>
		<value>[다른 컴퓨터IP]:50090</value> #네임노드말고 딴거
	</property>
</configuration>
	
	4)값 채우고 저장/종료

---------------------------------------------------------

4.MapReduce 작업관련설정
	1)vi mapred-site.xml
	2)<configuration></configuration> 속에
	3)
<configuration>
	<property>
		<name>mapred.job.tracker</name>
		<value>[NameNodeIP]:9001</value>
	</property>
</configuration>
		
	4)값 채우고 종료



------------------------------------------------

5.사용할 컴퓨터 등록
	1)vi workers
	2) 'localhost'지우고
	3)사용할 컴퓨터 ip주소 다 등록
		ex)1.1.1.1
		    2.2.2.2(엔터처리)
		    3.3.3.3
	4)등록할내용 다 입력했으면 엔터처리 한번하고
	5)저장후 종료


------------------------------------------------------------
설정한것들 => 나머지 컴퓨터로 전송
	1.최상위 경로로 이동
	2.설정이 끝난 hadoop폴더 압축(압축파일 이름 : myHadoop.tar.gz)
	3.알드라이브 - 새로고침 - 윈도우 편한위치에 저장
	4.압축파일을 알드라이브를 이용해서 각 컴퓨터에 보내기
	5.압축해제
		[NN제외 나머지 컴퓨터]
			압축해제 => 압축파일 삭제

--------------------------------------------------------------------

[전부 다]
	Hadoop설정 잘 되어있나 확인
---------------------------------------------------------------------

Hadoop실행 전에

1. 찌꺼기폴더 삭제	
	전부다 ] rm -rf ~/hadoopTmpData

2. 하둡 폴더로 이동
	NN만]
		cd ~/hadoop/hadoop-3.3.3

3. 하둡시스템 포맷
	NN만]
		bin/hadoop namenode -format
		bin/hadoop datanode -format

4.시작
	NN만]
		sbin/start-all.sh

5.확인
	전부다]
		jps >> 확인

6.끄기
	NN만]
		sbin/stop-all.sh

jps 다 안나왓으면 - 설정쪽에 문제 있을 가능성높음
6번 실행후 설정파일들 한번더 확인-> 1~5 재실행






































